# F1 Race Strategy Optimizer ğŸï¸

This project aims to predict the optimal race strategy for a Formula 1 race by modeling tire degradation, pit stop deltas, and other race variables. The system uses historical data to train a suite of models and an optimization algorithm to recommend the best pit stop laps and tire choices to minimize total race time.

## âœ¨ Tech Stack

* **Data Collection & Versioning**: `FastF1`, `Python`, `DVC`, `Dagshub`
* **Data Orchestration & Warehousing**: `Docker`, `Astro CLI`, `Airflow`, `PostgreSQL`
* **Model Training & Tracking**: `Scikit-learn`, `XGBoost`, `MLflow`
* **Deployment & CI/CD**: `Flask`, `Render`, `GitHub Actions`
* **Frontend**: `Streamlit`

## ğŸ—ï¸ Project Architecture

1.  **ETL Pipeline**: A Python script using **FastF1** fetches historical race data. **DVC** versions this data and pushes it to **Dagshub**.
2.  **Data Ingestion**: An **Airflow** DAG, running in a Docker container managed by **Astro CLI**, orchestrates the data pipeline. It extracts raw data, transforms it into features, and loads it into a **PostgreSQL** database.
3.  **Model Building**: A training script fetches feature data from Postgres, trains the prediction models, and logs experiments, parameters, and artifacts to **MLflow**.
4.  **Backend API**: A **Flask** application loads the best model from the MLflow registry and exposes an API endpoint for inference. This API is containerized and deployed on **Render**.
5.  **CI/CD**: **GitHub Actions** automates the entire process. On a push to `main`, it runs tests, triggers the model training pipeline, and if a new model is promoted, it deploys the updated Flask API to Render.
6.  **Frontend**: A **Streamlit** application provides a user-friendly interface to interact with the model by calling the deployed Flask API.

## ğŸ“ Project Structure

f1-strategy-optimizer/
â”‚
â”œâ”€â”€ .dvc/                   # DVC metadata
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/          # GitHub Actions CI/CD workflows
â”‚       â””â”€â”€ main.yml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw data pulled by FastF1 (tracked by DVC)
â”‚   â”‚   â””â”€â”€ race_data.csv.dvc
â”‚   â””â”€â”€ processed/          # Processed data for modeling (tracked by DVC)
â”‚       â””â”€â”€ features.csv.dvc
â”‚
â”œâ”€â”€ dags/                     # Airflow DAG definitions
â”‚   â””â”€â”€ etl_dag.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                # Flask API
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ model/              # Model training and evaluation scripts
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â””â”€â”€ predict.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/               # Data collection and processing scripts
â”‚   â”‚   â””â”€â”€ make_dataset.py
â”‚   â”‚
â”‚   â””â”€â”€ frontend/           # Streamlit UI
â”‚       â””â”€â”€ app.py
â”‚
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile              # For Airflow environment (managed by Astro)
â”œâ”€â”€ packages.txt            # OS packages for Docker
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # This file

