# .github/workflows/model_training.yml
# This workflow automates the model training and registration pipeline.

name: "Automated Model Training"

on:
  # This allows the workflow to be triggered automatically after the
  # "Automated Data Pipeline" workflow completes successfully.
  workflow_run:
    workflows: ["Automated Data Pipeline"]
    types:
      - completed
  
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

jobs:
  run-model-pipeline:
    # This condition ensures the job only runs if the data pipeline was successful
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: pip install -r requirements-model.txt

      - name: Configure DagsHub DVC Remote
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          dvc remote modify origin --local auth basic
          dvc remote modify origin --local user ${{ secrets.DAGSHUB_USERNAME }}
          dvc remote modify origin --local password $DAGSHUB_TOKEN
      
      - name: Pull Processed Data
        run: |
          # Pull only the final processed data file needed for training
          dvc pull data/processed/processed_data.csv -r origin

      - name: Run Model Training Script
        # This step runs our wrapper script, which in turn calls train.py
        # It requires the MLflow credentials to be set as environment variables.
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          PYTHONPATH=src python scripts/run_training.py